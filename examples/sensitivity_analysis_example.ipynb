{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from pytolemaic.pytrust import SklearnTrustBase\n",
    "\n",
    "from pytolemaic.utils.dmd import DMD\n",
    "from pytolemaic.utils.general import GeneralUtils\n",
    "from pytolemaic.utils.metrics import Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 13) (178,)\n"
     ]
    }
   ],
   "source": [
    "# get dataset\n",
    "from sklearn.datasets import load_wine\n",
    "data = load_wine()\n",
    "x = data.data\n",
    "y = data.target\n",
    "feature_names = ['feature #%d' % k for k in range(x.shape[1])]\n",
    "print(x.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of missing valies in x: 100 out of 2314\n"
     ]
    }
   ],
   "source": [
    "rs = numpy.random.RandomState(0)\n",
    "# let's add some missing values\n",
    "nan_locs = numpy.ones(numpy.prod(x.shape))\n",
    "nan_locs[rs.permutation(len(nan_locs))[:100]] = numpy.nan\n",
    "nan_locs = nan_locs.reshape(x.shape)\n",
    "x = x * nan_locs\n",
    "print(\"number of missing valies in x:\", numpy.sum(numpy.isnan(x)), \"out of\", numpy.prod(x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train/test sets\n",
    "perm = rs.permutation(len(y))\n",
    "ntrain = len(y)-60\n",
    "xtrain, xtest = x[perm[:ntrain],:], x[perm[ntrain:],:]\n",
    "ytrain, ytest = y[perm[:ntrain]], y[perm[ntrain:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('Imputer',\n",
       "                 SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
       "                               missing_values=nan, strategy='mean',\n",
       "                               verbose=0)),\n",
       "                ('Estimator',\n",
       "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                        criterion='gini', max_depth=None,\n",
       "                                        max_features='auto',\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=10, n_jobs=None,\n",
       "                                        oob_score=False, random_state=0,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train RandomForest with imputation preprocess\n",
    "#imputation preprocess is required for sensitivity to missing values\n",
    "\n",
    "estimators = []\n",
    "estimators.append(('Imputer', SimpleImputer()))\n",
    "estimators.append(('Estimator', RandomForestClassifier(n_estimators=10, random_state=0)))\n",
    "estimator = Pipeline(steps=estimators)\n",
    "    \n",
    "estimator.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some definitions \n",
    "\n",
    "metric_of_interest = Metrics.recall.name\n",
    "\n",
    "## set splitting strategy\n",
    "splitter = 'shuffled'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init Pytrust object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "    ## sample meta data (e.g. sample weight) - empty in this example\n",
    "    sample_meta_train = None\n",
    "    sample_meta_test = None\n",
    "\n",
    "    # set the feature names names\n",
    "    columns_meta = {DMD.FEATURE_NAMES: feature_names}\n",
    "\n",
    "    pytrust = SklearnTrustBase(\n",
    "        model=estimator,\n",
    "        xtrain=xtrain, ytrain=ytrain,\n",
    "        xtest=xtest, ytest=ytest,\n",
    "        sample_meta_train=sample_meta_train, sample_meta_test=sample_meta_test,\n",
    "        columns_meta=columns_meta,\n",
    "        metric=metric_of_interest,\n",
    "        splitter=splitter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensitivity Analysis Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MISSING': {'META': {'N_FEATURES': 13,\n",
      "                      'N_LOW': 5,\n",
      "                      'N_NON_ZERO': 8,\n",
      "                      'N_ZERO': 5},\n",
      "             'SENSITIVITY': {'feature #0': 0.03508,\n",
      "                             'feature #1': 0.03508,\n",
      "                             'feature #10': 0.07016,\n",
      "                             'feature #11': 0.0,\n",
      "                             'feature #12': 0.12591,\n",
      "                             'feature #2': 0.0,\n",
      "                             'feature #3': 0.0,\n",
      "                             'feature #4': 0.0,\n",
      "                             'feature #5': 0.10524,\n",
      "                             'feature #6': 0.44551,\n",
      "                             'feature #7': 0.0,\n",
      "                             'feature #8': 0.06101,\n",
      "                             'feature #9': 0.12202}},\n",
      " 'SHUFFLE': {'META': {'N_FEATURES': 13,\n",
      "                      'N_LOW': 6,\n",
      "                      'N_NON_ZERO': 7,\n",
      "                      'N_ZERO': 6},\n",
      "             'SENSITIVITY': {'feature #0': 0.12097,\n",
      "                             'feature #1': 0.0,\n",
      "                             'feature #10': 0.03478,\n",
      "                             'feature #11': 0.0,\n",
      "                             'feature #12': 0.26493,\n",
      "                             'feature #2': 0.0,\n",
      "                             'feature #3': 0.0,\n",
      "                             'feature #4': 0.0,\n",
      "                             'feature #5': 0.03478,\n",
      "                             'feature #6': 0.39785,\n",
      "                             'feature #7': 0.0,\n",
      "                             'feature #8': 0.02571,\n",
      "                             'feature #9': 0.12097}},\n",
      " 'VULNERABILITY': {'IMPUTATION': 0.40447,\n",
      "                   'LEAKAGE': 0.00967,\n",
      "                   'OVERFIIT': 0.67937}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    sensitivity_report = pytrust.sensitivity_report()\n",
    "    pprint(sensitivity_report.simplified_keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'QUALITY': 1.0,\n",
      " 'recall': {'CI_HIGH': 0.95014, 'CI_LOW': 0.89584, 'SCORE_VALUE': 0.91707}}\n"
     ]
    }
   ],
   "source": [
    "pprint(pytrust.scoring_report().simplified_keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quality report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_set': {'overall_quality': 0.9407896889005202,\n",
      "              'quality_components': {'ci_ratio': 0.9407896889005202,\n",
      "                                     'separation_quality': 1.0}},\n",
      " 'train_set': {'overall_quality': 0,\n",
      "               'quality_components': {'imputation': 0.59553,\n",
      "                                      'leakage': 0.99033,\n",
      "                                      'overfit': 0.32062999999999997}}}\n"
     ]
    }
   ],
   "source": [
    "pprint(pytrust.quality_report().simplified_keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
